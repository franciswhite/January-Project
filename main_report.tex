\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}

\title{Sticks and Stone:\\
{\small \tb{Maybe a subtitle would help, e.g. ``Offensive language use through the lens of pragmatic language use'' or ``A game-theoretic analysis'' or whatever you fancy. Just a little more information}}}
\date{Date quo: 1.02.17}

\usepackage{mathptmx} % "times new roman"
\usepackage[a4paper,bindingoffset=0.2in, left=5cm,right=4cm,top=4.5cm,bottom=6.5cm,footskip=.25in]{geometry} % for submission requirements
\usepackage{amssymb}
\usepackage{amsmath, amsthm}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{comment}


\usepackage{color}
\newcommand{\tb}[1]{\textcolor[rgb]{.8,.33,.0}{[TB: #1]}}% prints in orange
\usepackage[normalem]{ulem}

\bibliography{references.bib}
\begin{document}
\maketitle

\section{Introduction}
When Donald Trump, the current president of the United States of America \tb{Unnecessary elaboration, you're trying to save space}, was asked to explain calling women \tb{``}fat pigs'', \tb{``}dogs'', \tb{``}slobs'' and \tb{``}disgusting animals'' his reply was \tb{I won't continue marking quotation marks, but please make sure that you do change them}:
\textit{I’ve been challenged by so many people, I don’t frankly have time for total political correctness. And to be honest with you, this country doesn’t have time either'}. \tb{Add reference for quote}
%https://www.theguardian.com/us-news/2016/nov/30/political-correctness-how-the-right-invented-phantom-enemy-donald-trump
In contrast to \tb{Donald} Trump, the authors of the present paper had time. We provide a formal framework in order to analyze the pragmatic phenomenon of harmful use of language. \tb{The last two sentences are a bit too informal. Maybe pose the issue as questions; e.g. ``If particular word choices are, as tacitly suggested by Donald Trump, not a central element in the transmission of information and may even be an impediment to the speaker; why may speakers notwithstanding refrain from using certain expressions over others? In the following, we address this question in the context of ... {\em short blurb about the approach you take to model the phenomenon}''.}

\tb{This goes in the same paragraph as above. It connects neatly} We are interested in explaining under which circumstances speakers \sout{will be} \tb{are} disposed to alter their way of expressing themselves. Specifically, we \sout{will} analyse \sout{the situation} \tb{situations} where a speaker is indifferent about various communicative options \tb{This is pretty vague. Maybe ``indifferent about the use of one expression over the other''}, while \sout{the} \tb{her} audience dislikes some of the alternatives \tb{has a clearn preference over them}. \tb{``That is, we model a situation in which...''} Although the wording of a message \tb{maybe ``utterance'' is better} might not affect the transfer of information, it can have an impact on the listener. Obvious cases \sout{in point} are racial slurs and so-called ''trigger words'' which cause listeners suffering from postraumatic stress disorder (PTSD) to re-live past trauma \cite{fagan2004confronting, yehuda2002post}. \tb{(i) references before punctuation, (ii) be consistent in how you mark technical terms (trigger words), natural language expressions, and quotes.} So although two expressions might be semantically identical, choosing one over the other can have a substantial effect on actual communication, depending on who is speaking, and, crucially, who is listening. We thus take the pragmatic slogan seriously that there is far more to communication than the literal meaning of the expressions employed \tb{(c.f. Grice 1975)}.
When studying the use of language as the transfer of information, the issue becomes to explain how there can coexist equally good - expressive, accurate, etc. - forms of communication, yet some options are used rather than others.

\sout{Based on our model} we will present three core results: First, we \sout{will} offer a formal explanation for the reason why offensive use of language is so persistent. Given that there are many ways of putting things, how come people still offend and harm each other? \tb{I'd take out this question, it's just a rephrasing of what you said above}  Second, we \sout{will} argue that there is potential for better communication, benefiting everyone \tb{Either explain what better means, briefly and in informal terms, or say that you will make this precise later}. Third, we will argue that the degree of ''empathy'' language users exhibit is of crucial importance to reap \sout{those} \tb{these} benefits. \tb{To save space and make everything more concise, you could add the references to the appropriate sections in this paragraph. E.g. In \S N.N we offer...} or put section references in brackets at the end of each points.

We \sout{will rely on} \tb{Maybe just: To this end, we use} game theoretic models of the \textit{Iterated Best Response} (IBR) family \tb{(i) why the plural in models? It's not so relevant what the model is called nor that its a family of models. Rather, stress informally what it models, e.g. rational language use between agents that reason about each others linguistic choices. Also, add a reference e.g. to Franke \& J\"ager 2014.}. This approach looks to explain and predict pragmatic inferences of natural language users by modeling a \sout{forth-and-back} \tb{back-and-forth} reasoning \sout{taking place} between two agents engaged in conversation \tb{(Grice 1975)}.
Our \sout{main} formal \sout{addition to such models} \tb{contribution} is \sout{that we want} to forgo the common assumption that it is exclusively the player sending a message for whom this \tb{What is ``this''? Maybe better: ``word choice''} \sout{is} is costly. \tb{Instead,} We will look at signaling games \tb{What is a signaling game? Maybe just ``situations''} where costs are conncected \tb{What does cost connected to mean here? Maybe ``where not only the sender incurs a cost in message choice, but also the message's recieiptn} not only to the sender, but also to the recipient.
We will offer some take on these questions by following this outline:
\begin{enumerate} %need to make this prose. but will do so later, once order is established. Also, we will need to find some more sensible way to structure the text into sections with actually meaningful headers.
\item Brief Introduction to Signaling Games
\item Introduction to the IBR Model
\item Sticks and Stones
\item Conclusion, Unexplored Topics \& Further Research
\end{enumerate}

\section{Game theory and pragmatics}
\subsection{Signaling games}
\tb{We model language use as a ...} Signaling games are sequential games between two players: a sender and a receiver \tb{(Lewis 1969}). In the context of linguistic modeling one can usually think of the sender as a speaker and of the receiver as a listener \tb{This can be skipped}. The game is playerd in \sout{some} \tb{a} particular state of the world, formally an element of set $T$ which represents possibles ways the world could be. Only the sender knows which state this happens to be. \tb{Mention here what the point is: The sender has access to the state and wants to transfer the information to the receiver. Receiver has no access, but receives a messages based on which she tries to infer the appropriate $t \in T$.} The receiver, however, has some beliefs about the possible states. These beliefs are modeled with a probability measure, so that $T$ is sample space and $P_R$ is probability measure which is a function $P_R: T\rightarrow \mathbb{R}_{\geq 0}$ satisfying $\sum_{t\in T}P_R(t)=1$. \tb{This is formally correct, but can also (mostly) be skipped by saying that the beliefs are a probability distribution over states, $P_R \in \Delta(T)$. No need to go overboard with the math.}

The game is then played such \tb{This sounds odd. ``The game is played as follows''}: After the sender observes the true state of the world $t$ she sends some message $m_i$ out of a set of messages $M$. \tb{This can be shortened to ``... some message $m_i$, $m_i \in M$''}
The receiver then observes \sout{which element} \tb{message} $m_i$ \sout{from $M$ was sent} and chooses some action $a_j$ from a set of actions $A$.
The players' respective utility is given by functions $u_S$ and $u_R$. They take as arguments the state the players find themselves in and the action performed by the receiver, so that $u_S(t,a)$ and $u_R(t,a)$. We will only consider cooperative games, so that $u_S(t,a)=u_R(t,a)$ for $\forall t\in T$ and $\forall a\in A$.
What message is being sent does not directly affect the players' payoff, for the message is not part of the utility function \tb{This is not true. It does affect their payoff, but this is not captured by not having messages be part of the utility functions of the players, that's why they need to look different when you are considering costly signaling. I would not worry about this though. Instead, I would skip the formal exegesis you're giving here about utilities and completely background it. Give an informal explanation of what's going on and on how message cost affects things. You introduce it's effect anyway below}. Hence, the only effect a message can have is by altering the receiver's belief \tb{Not also the sender's choice?}. Different beliefs have the potential to alter her optimal action and thereby to affect both players' payoff.
\sout{The} \tb{A} sender's strategy is a function from the set of states $T$ to the set of messages $M$; \tb{a} \sout{the} receiver's strategy is a function from the messages $M$ to the set of actions $A$.
%We could already introduce priors, cost and expected utility here.
We call a strategy \textit{pure} if a player will choose a some action with certainty, that is, always, when confronted with a given situation. In contrast to pure strategies stand
\textit{mixed} strategies where players will choose from various actions, each with a certain probability.

\subsection{Extension towards pragmatics}
Game theoretic modeling has been used for of a variety of phenomena related to information transmission. For notable examples in economics and biology, see \cite{spence1973job, smith1982evolution, cho1987signaling} \tb{Put in brackets after first sentence}.
In linguistics, it was applied in attempts to obtain a firmer conceptual grip on Gricean pragmatics. \tb{reformulate}
%References!
Here the communication between (rational) agents is thought of as a game played between interlocutors. Formulating situations where pragmatic phenomena arise with mathematical precision helps in different ways: On the one hand, it allows bridging the gap between theoretical work on pragmatics and \sout{actual} experimental data with language users \tb{(e.g. Frank \& Goodman 2012, ...)}. More specifically, it generates testable predictions about language use under a variety of parametrizations, as pertaining to the agent's (limited) rationality, cognitive ability to think multiple steps ahead, their preferences and methods of deciding on what action to take - so-called \textit{choice rules} %References? perhaps paolo's phd thesis?
 - or their beliefs about the world. On the other hand, such models ought \tb{This sounds pretty normative} to provide insight into how agents actually arrive at the linguistic behavior they exhibit. %Do you like the last sentence? or do you prefer "...arrive at their linguistic behaviour"?
 Indeed, models concerned with pragmatic behavior of linguistic agents are caught between the pressure of trying to accurately predict and fit experimental data and the hope to realistically capture one or the other aspect of a pragmatic phenomenon - to represent ''what actually is going on'', so to speak. \tb{This sounds very critical for a paper that then goes on to use these kinds of models}

The family of models we will be concerned with tries to capture the agents' mutual reasoning about each other \tb{Isn't this true of all pragmatic models of rational language use?}. Which action the players deem optimal for them and perform depends on a process of reasoning about what the respective other believes. The model tries to capture this process of reasoning about what the respective other does, believes that her opponent will do, believes what her opponent will believe that she will do, and so forth.
\subsection{The IBR model}
We are going to use an IBR model to provide our solution concept \tb{Is that so? If so, what is a solution concept?}. %WHY? %What is a solution concept?
For details and discussion see \cite{franke2009signal} and \cite{franke2014pragmatic} \tb{This in brackets at the end of previous sentence}. IBR relies on an explicit representation of the agents' beliefs about each other. The interlocutors beliefs are spelled out in a round-for-round manner in order to capture what intuitively could be the described as the epistemic dynamic of: ''I think that you think that I think that you think...etc.''. Language users are represented to have some hierarchically ordered level of sophistication which correspond to the number of steps an agent can reason forth and back \tb{The standard expression is always ``back and forth'', it sounds odd to invert them} between herself and the other agents. The reasoning chain formed by such steps is then a sequence of iterated optimal responses. \tb{This chain} \sout{It} is bounded by the maximal depth a player of a given level of sophistication - or strategic type - can go to.

Entirely unsophisticated types, players who do not take the opponents reasoning into account at all and are thus completely unstrategic, are assigned the level-0. In the games under discussion in this paper this will mean that senders of level-0 will be only concerned with saying whatever is true according to the semantics of the language fragment in question, while receivers of that level will always interpret a message they receive literally. An agent of level-$k$ then forms some belief about the other's behavior who, by assumption, is of some level $l$, where $k\geq l$. Intuitively, this can be interpreted as the player looking down the sophistication hierarchy in order to build some rational expectation of what the other of some specified level $l\leq k$ will do. It is common to assume for simplicity that players of level $k$ expect their opponents to reason exactly one step less than themselves and are thus of level $k-1$. \tb{Do you make this assumption?}

As in standard signaling games, $T$ is the set of states the players can be in, $M$ the set of messages at the sender's disposal and $A$ the set of actions from which the receiver can choose. We assume that $T,M$ and $A$ are finite sets, $|M|=m$, $|T|=n$ and $|A|=a$  A sender strategy is a row-stochastic $(n \times m)$-matrix $S$, and a receiver strategy is a row-stochastic $(m\times a)$-matrix $R$. By way of example, here are two strategies for a game with $|S|=|A|=3$ and $|M|=2$, so three states and actions, and two messages. \tb{As noted in your comments: I think it's not necessary to make this explicit. Background it.} \\
%Do we need the examples? Do we have space for the examples?
%This whole section can be made shorter.
\begin{equation*}
\sigma =
    \bordermatrix{
          & m_1 & m_2    \cr
      t_1 & 0.2 & 0.8  \cr
      t_2 & 0.4 & 0.6  \cr
      t_3 & 1 & 0
    } \quad
\rho =
    \bordermatrix{
              & a_1 & a_2 & a_3    \cr
          m_1 & 0.5 & 0.5 & 0  \cr
          m_2 & 0.8 & 0.1 & 0.1
        }
\end{equation*}

When the sender observes some state, her strategy determines with which probability she chooses from the different messages; likewise for the receiver, but with messages and actions. The rows in the strategy matrices thus represent the situations where the players get to decide, and the respective entries in the row describe the probabilities with which they opt for the move in that column. \tb{More concisely, $P(m|t,S) = S_{tm}$ and likewise $P(a|m,R) = S_{ma}$.}  The sender, in this example, would choose $m_1$ with probability $0.2$ upon observing $t_1$, and with probability $1$ when observing $t_3$. The receiver, in turn, would choose $a_1$ and $a_2$ each with probability $0.5$, while never playing $a_3$, when receiving $m_1$ from the sender.
%Here is the place to use the definition of pure and mixed strategies. If we actually want to define them before.

The meaning \tb{Here better ``semantics''} of the language fragment in question is modeled as a $(n \times m)$-matrix. If some state $t_i$ semantically warrants \tb{This is an odd formulation. Usually, you'd talk about ``truth'' of a message in a state or that a message ``holds'' in a state} the utterance of some message $m_j$, then the entry $x_{ij}$ in the matrix will be $1$, otherwise $0$. This matrix reporting the boolean values is called the \textit{Boolean Matrix} and denoted by $B$. For the purpose of illustration, an example where both $t_1$ and $t_2$ can be distinctly expressed, but the game contains no message meaning $t_3$: \tb{This can also be backgrounded. Or directly introduce the matrix you will use later}\\
%Do we need this example? I would say it's the first to go if we run short of space.
\begin{equation*}
B =
    \bordermatrix{
              & m_1 & m_2    \cr
          t_1 & 1 & 0  \cr
          t_2 & 0 & 1  \cr
          t_3 & 0 & 0
        }
\end{equation*}

The strategies of level-0 type are represented by the normalized boolean matrix. Normalization here simply means a mapping of some $(m\times n)$-matrix $A$ onto some other $(m\times n)$-matrix $B$ such that $B_i\propto A_i$ if $\sum_j (A_{ij})>0$ and $B_{ij}=\tfrac{1}{n}$ otherwise. In the case of the receiver the transposed boolean matrix is normalized. \tb{First, say intuitively what this means: Sender sends whatever is true according to the literal meaning of messages in $B$, receiver interprets messages literally as well.}

More sophisticated players are modeled as to have some belief about the interlocutors behavior. For now we will assume that players have unbiased beliefs, meaning that there are no further restriction imposed - for example, that some player simply disregards a possible strategy. A belief is unbiased if all elements $x\in X$ of some (finite) set X are deemed to be equally probable. All $y\not\in X$ are assigned probability zero. So that each option is considered equally likely. We thus follow Franke's argument for
%Franke Phd also contains probabilistic argument about the Principle of Indifference. We should mention it.
 using unbiased beliefs about possible opponent behavior as it allows us to simplify the mathematics and allows for more straightforward computation in linguistic applications. Formally, if $X$ is some ordered set of strategies of cardinality $\mathbb{C}$, then the set of beliefs $\Pi$ is defined as\\
\begin{equation*}
\Pi(X)=\{\sum_{x\in X} \dfrac{1}{\mathbb{C}}X\}
\end{equation*} %i don't understand this equation

%HERE WE NEED A PARAGRAPH ABOUT PRIORS FOR RECEIVER AND COST VECTORS IN GENERAL. this is also the chance to mention the vector notation later applied.

Finally, we define the notion of \textit{best response} given a set of beliefs. A sender's best response to some receiver strategy $R$ is any strategy that maps each state to that signal which maximizes the expected utility. In case $n$ signals are tied for expected utility, the sender will play each with probability $\tfrac{1}{n}$.
%More formally speaking, the sender's best response to some receiver strategy is\\
%\begin{equation*}
%BR_S(R)=\{s\in S | s_{ij}=1\implies j \in arg_kmax(U_S T(\rho)-c)_ik)\}
%\end{equation*}
A receiver's best response to a sender's strategy $S$ is defined almost analogously. Except that there may be so-called \textit{surprise messages} $m_j$ for which $R{ij}=0$, for all $i$. These are messages the sender will use with probability 0, that is, never. Since strategies are plans of action for every conceivable contingency that might arise in the course of a game, we'll assume that a receiver will then play each option with probability $\tfrac{1}{|A|}$.
%I don't think we need what's commented out right below. Tell me if I am wrong.
%As the sender has a set of beliefs $\Pi$ about the receivers possible behavior, the set of best responses is the union of all best responses to these possible strategies: $BR(\Pi=\Cup\{BR(\pi)|\pi\in\Pi\}$.

\tb{I think this section can be made A LOT shorter. You just need to introduce what you need. E.g. you can completely skip the whole ``unbiased beliefs'' bit. If you want to show that you did your duty just add a footnote and say ``This corresponds to ... unbiased beliefs ... . We background these details for ease of exposition, but see Franke \& J\"ager for details''. This is normal for a non-journal paper. You just don't have space to discuss all of this. And the reader has no patience. Give them enough to understand what you need and give references to show that you know that there are other ways of doing it. However, if this choice is not super important for your paper, then do not ever discuss it explicitly}

\section{Harmful signaling}
Let us now say that two people sharing some language engage in conversation, one as a speaker, the other as a listener. The speaker would like to communicate what kind of work a mutual acquaintance of the two does. The listener does not yet know what her occupation happens to be. The acquaintance could either be an ecologist or a geologist. To transfer this knowledge the speaker can utter either ''She's an ecologist.'', ''She's a professional treehugger, stupdily trying to protect plants and stuff.'', ''She's a geologist.'' or ''She's a professional stonehugger, stupidly looking at rocks and stuff.''. Assume that uttering any of the first two is true just in case the person is an ecologist and the last two if she's a geologist. As both of the two well know, the listener cares dearly for the environment, while the speaker does not. The listener, although she understands perfectly well what the speaker is trying to convey to her, would be deeply offended by her uttering the word ''treehugger''. The speaker herself couldn't care less what words are used when talking about ecology, as long as the message comes across and the hearer adopts the right belief about the mutual acquaintance's profession. However, the speaker has a deep-rooted fear of rocks. Hearing the word ''stonehugger'' sends chills down her spine.

We will now use the IBR model to analyse the above communication. We will show how these message preferences do not affect successful communication but only make the communication non-optimal. We model message preferences by defining a cost vector for both sender and receiver.
\subsection{The model}
We have two players, $P_1$ and $P_2$. For now, let $P_1$ be the sender and $P_2$ the receiver. Let $T=\{t_{geo}, t_{eco}\}$, where $t_{geo}$ is a world where the acquaintence is a geologist, and in $t_{eco}$ an ecologist. We let both worlds be equally likely. We define the communication to be successful if the receiver adopts a belief which matches the state of the world. Both sender and receiver receive a payoff if communication is successful. Let that payoff be $a$ in case of success and 0 otherwise, where $a>0$.

The set of messages is $M=\{m_{geo}, m_{stone}, m_{eco}, m_{tree}\}$. Its semantics are given by $B$.
 \begin{equation*}
 B =
 \bordermatrix{
            & m_{geo} & m_{stone} & m_{eco} & m_{tree}    \cr
   t_{geo}  &       1 &         1 & 0       & 0 \cr
   t_{eco}  &       0 &         0 & 1       & 1
 }
 \end{equation*}

$m_{stone}$ being played inflicts a cost of $\alpha$ to $P_1$, while $m_{tree}$ bears cost $\beta$ for $P_2$, where $a>\alpha,\beta>0$.\footnote{Communicating is always preferable to non-communication and no expressions can only be harmful.} The two cost vectors are thus \tb{This takes up a lot of space. Just say that messages are ordered as above, and cost vector are ordered in the same manner. Just put them inline, no labeling necessary}

  \begin{equation*}
  c^1 =
  \bordermatrix{
             & m_{geo} & m_{stone} & m_{geo} & m_{tree}    \cr
             &       0 &         \alpha & 0       & 0
  }\qquad
  c^2 =
    \bordermatrix{
               & m_{geo} & m_{stone} & m_{geo} & m_{tree}    \cr
               &       0 &         0 & 0       & \beta
    }
  \end{equation*}

Furthermore, the receiver is unbiased with respect to which state holds. \tb{You should introduce the model with this example immediately. This saves space and directly shows how you're using the model. That is, all of this section and the preceding two could be a single section that is much shorter}
%Do we even need this assumption?
%Usually language users will encounter the expressions of their language many times over the course of their communicative lives - both as listeners as well as speakers. To capture this we'll posit a third player - nature - which decides at the beginning of the game who of the two players gets to talk and who gets to listen. As rational language users they will need to have some plan of action for all roles, states of the world or messages they encounter.
%Use this section elsewhere or delete.
\subsubsection{Game play}
As a first step, we determine what the naive players' strategies are:\\
\textbf{Level-0 Players}\\
\begin{equation*}
S_0=Norm(B)=
\bordermatrix{
            & & & &    \cr
 &       0.5 &         0.5 & 0       & 0 \cr
 &       0 &         0 & 0.5       & 0.5
 }\quad
R_0=Norm(B^T)
\bordermatrix{
            &  & \cr
    & 1 & 0 \cr
     & 1 & 0 \cr
     & 0 & 1 \cr
     & 0 & 1 \cr
 }
\end{equation*}
The naive sender has no principle to decide between sending either $m_{geo}$ or $m_{stone}$ when whishing to communicate $t_{geo}$. \tb{What does ``having a principle'' mean? Informally, she has no preference to send one over the other, because both messages are true in the state -- so she doesn't care and picks randomly} Similarly she has no principle to decide between sending either $m_{eco}$ or $m_{tree}$ when whishing to communicate $t_{eco}$. This is represented by her sending each message half of the time. So she plays a mixed strategy. The receiver's actions are clearly determined by a pure strategy.\\

What is the best response of the level-1 hearer and speaker? Following the IBR procedure we transpose $R_0$, subtract the cost vector $c^1$ and check row-wise for the best response to obtain $S_1$. \tb{No need to spell this out procedurally. Explain intuitively what higher level players do, and then just go straight to the formula. The step-by-step derivations are cumbersome and can be confusing. You have not said, in all generally, how they are computed up to here. So it's hard to digest for a na\"ive reader}  We proceed analogously for the receiver, the main difference being in this case that the receiver faces some actual cost, $c^2$. This then yields strategies for level-1 players:\\ %TODO : we need to add the prior. %
\textbf{Level-1 Players}\\
\begin{equation*}
% These matrices look strange when rendered
S_1= BR_S(R^T_0-c^1)=
BR_S(
\bordermatrix{
            & & & &    \cr
 &       1 &         1 & 0       & 0 \cr
 &       0 &         0 & 1      & 1
 }
-
\bordermatrix{
            & & & &    \cr
 &       0 &         \alpha & 0       & 0 \cr
 }
)
\end{equation*}
\begin{equation*}
=BR_S(
\bordermatrix{
                & & & &    \cr
     &       1 &         1-\alpha & 0       & 0 \cr
     &       0 &         0-\alpha & 1      & 1
 }
 )
=
\bordermatrix{
                 & & & &    \cr
      &       1 &         0 & 0       & 0 \cr
      &       0 &         0 & 0.5      & 0.5
  }
\end{equation*}
\begin{equation*}
R_1=BR_R({S_0}^T-{c^2}^T)=
BR_R(
\bordermatrix{
            &  & \cr
    & 0.5 & 0 \cr
     & 0.5 & 0 \cr
     & 0 & 0.5 \cr
     & 0 & 0.5 \cr
 }
-
\bordermatrix{
  & \cr
    & 0 \cr
     & 0 \cr
     & 0 \cr
     & \beta \cr
 }
)
\end{equation*}
\begin{equation*}
=
BR_R(
\bordermatrix{
            &  & \cr
    & 0.5 & 0 \cr
     & 0.5 & 0 \cr
     & 0 & 0.5 \cr
     & 0-c & 0.5-c \cr
 }
 )
=
\bordermatrix{
            &  & \cr
    & 1 & 0 \cr
     & 1 & 0 \cr
     & 0 & 1 \cr
     & 0 & 1 \cr
 }
\end{equation*}
We see that $R_1=R_0$ thus we conclude that $S_2=S_1$. \tb{What does this mean, informally? i.e., fixed point of the reasoning process. No need to go higher}
\begin{equation*}
R_2=BR_R({S_1}^T-{c^2}^T)=
\bordermatrix{
            &  & \cr
    & 1 & 0 \cr
     & 0.5 & 0.5 \cr
     & 0 & 1 \cr
     & 0 & 1 \cr
 }
\end{equation*}
$S_3=S_2$ and $R_3=R_2$. Since $S_3$ and $R_3$ are the best responses to each other, we have reached a stable strategy.
Some remarks about these strategies are in order. First, the sender will never send the message she finds offensive. \sout{This makes perfect intuitive sense} \tb{Never tell the reader that something is clear or intuitive. Maybe it's not so intuitive for them. Rather, say ``Intuitively, this is so because...''}, because she has a non-costly alternative which spares her from uttering ''stonehugger''. Second, the receiver views $m_{stone}$ as a surprise message \tb{What does this mean?}. Although the sender will never play it, the receiver still needs has some plan of action for that contingency. Thirdly, while a sender of level zero still harms herself by blindly sending a costly message, senders above level zero will stop doing so. Thus, $m_{stone}$ will not be seen on higher levels.

\subsection{Problem characterization}
Here's what's unsatisfactory with this situation: Successful communication yields equal payoffs of $a$ for both players. Indeed, the \textit{sender's payoff} is always $a$, for the the strategy pair $<S_3,R_3>$ entails successful communication. For the receiver, however, the story is different. \tb{Above, you claimed payoffs are equal for both. Now you tell me that this is not true.} When $S_3$ is played and $t_{eco}$ holds, $(m_{tree}$ will be sent with probability 0.5. Since the probability of $t_{eco}$ is 0.5, $m_{tree}$ is sent in $\tfrac{1}{2}\times \tfrac{1}{2} = \tfrac{1}{4}$ of all cases on average, inflicting a cost of $\beta$. In expectation, she will thus obtain a mere payoff of $a-\tfrac{\beta}{4}$.

\begin{table}[h]
\centering
\caption{Expected Payoff for Level of Sophistication \tb{Always introduce a Table or Figure in the text, e.g., ``As shown in Figure X, ...''.}}
\begin{tabular}{lll}
                                    & Sender                                  & Receiver                                \\ \cline{2-3}
\multicolumn{1}{l|}{Level-0}        & \multicolumn{1}{l|}{$a-\tfrac{\alpha}{4}$} & \multicolumn{1}{l|}{$a-\tfrac{\beta}{4}$} \\ \cline{2-3}
\multicolumn{1}{l|}{Level-k, $k>0$} & \multicolumn{1}{l|}{$a$}                  & \multicolumn{1}{l|}{$a-\tfrac{\beta}{4}$} \\ \cline{2-3}
\end{tabular}
\end{table}

As a way of intuitive explanation, consider the positions the agents are facing in this game. Whether the receiver likes the message or not, she can always reason what her interlocutor wants to communicate to her. If the messages $m_{geo}$ or $m_{eco}$ are sent, she will chose the corresponding action, communication is successfull, so both players get their payoff and everyone is happy. If the message $m_{tree}$ is sent, however, she pays the associated cost. Still, she knows what the sender is trying to communicate and her best response will be to cooperate. Refusing to understand is not an option, for it would only add insult to injury; she would both pay the cost of hearing $m_{tree}$ and lose the payoff of understanding correctly. Because the sender can anticipate the receiver to behave this way, she does not need to care about sending either semantically correct message. \tb{What does ``semantically correct'' mean? Maybe ``either true message'' or ``either message that holds in this state'', etc..}

Now, actual language use is an activity which agents engage in repeatedly, sometimes as speakers, sometimes as listeners. To model this we assumed they play above game many times, each either role with equal probability \tb{Sentence not well formed}. Because \sout{the} \tb{``makes'' or so} game is symmetrical, we can simply interchange the expected payoffs for the two agents if they play in the other role. Over the course of a lifetime of conversation - a sufficient amount of linguistic interactions - the players can expect a utility of $\tfrac{1}{2}\times a + \tfrac{1}{2}\times (a-\tfrac{i}{4})=a-\tfrac{i}{8}$, for $i\in \{\alpha,\beta \}$. \tb{Maybe just say that this is their {\bf expected} utility in repeated interactions. Mentioning ``a sufficient amount of interactions'' raises a lot of questions and suggests a frequentist interpretation of expected utilities.}
%Notice that $a-\tfrac{o^i}{8} > a-\tfrac{o^i}{4}$, for any $o^i,a>0$.
%Check whether this is right.
%I would like to have high-indexed cost entries to the matrix depending on the players.

The crucial observation to make here is that the agents could have done better. To see this, imagine the agents only used $m_{eco}$ and $m_{geo}$ to communicate. If neither of them would ever inflict a cost and communication could still be reliably successfull, then both receive a full payoff of $a$.
Never playing costly messages formally means that the respective sender plays strategy $S_*$ where neither $m_{tree}$ nor $m_{stone}$ are ever played.
\begin{equation*}
S_*=
\bordermatrix{
            & & & &    \cr
 &       1 &    0      & 0       & 0 \cr
 &       0 &         0 & 1      & 0
 }\quad
R_*= \bordermatrix{
           &  & \cr
   & 1 & 0 \cr
    & 0.5 & 0.5 \cr
    & 0 & 1 \cr
    & 0.5 & 0.5 \cr
}
\end{equation*}

If this sender strategy is still able to convey the correct state, then everyone is better or at least as well off as before. In fact, such an improvement would imply satisfying a criterium for efficiency, namely the  \textit{Pareto optimality}.\tb{What does pareto optimality mean? Related back to your notion of ``better communication'' in the introduction. Pareto optimality captures a combination of behaviors where each agent fares best given the behavior of another agent -- this intuitively captures ... in communication} When the sender plays $S_*$ the receiver then plays $R_*$.

Formally, some strategy is Pareto optimal if it is not \textit{Pareto dominated} by some other strategy. Pareto domination, in its turn, is defined as follows:
Let $S$ be a set of strategies, $N$ a set of players, from 1 to n, and $u_i$ be each player's utility function. A strategy $s \in S$ Pareto dominates another strategy $s' \in S$ if:
\begin{equation*}
\forall i \in N: u_i(s) \geq u_i(s') \land \exists j \in N: u_j(s) > u_j(s')
\end{equation*}

If strategy $s'$ gives any player a higher utility than $s$, while no other player's utility decreases, we say that the $s'$ \textit{Pareto dominates} $s$. \tb{Again, you can just say what pareto optimality is, intuitively, if you don't use the formula later on}

We claim that the strategy pair $<S_*,R_*>$ is Pareto optimal. \tb{You claim? Can you show it? Or just say that it is the Pareto optimal one. Again, this can be done intuitively, much to the pleasure of a short-tempered reader. Or directly say that you will show this next} In the next chapter  \tb{section} we show how we can adjust the IBR model to reach the strategy pairs $<S_*,R_*>$ and show that $<S_*,R_*>$ is Pareto optimal.

+We claim that the strategy pair $<S_*,R_*>$ is Pareto optimal. In the next section we show that a small adjustment to our model suffices to reach the strategy pairs $<S_*,R_*>$.
+%It should be shown right here that $<S_*,R_*>$ is Pareto optimal. Then we can focus in the last section on how we actually get there. The argument should be easy: since expected payoffs don't get higher than $a$ and this strategies yields $a$ for both agents, no other strategy can dominate it. The important part is to compare the optimal payoff to the payoff they get under IBR strategies.
% Silvan
%Below these comments I have altered the text in parts. Consider the changes as suggestions.
+%In general, I think that our emphasis should lie on the fact that this solution naturally arises out of the technicalities of our modeling. It's not interesting that we personally believe that the solution to both players missing out on payoff is empathy. What's interesting is that we point to a small formal variation of our model which then happens to have an intuitive counterpart in the concept of empathy/altruism/also caring about others well-being. Ideally, we would introduce the technical changes while offering a running commentary of what they mean in intuitive terms.
+%Also, the paper is not geared anymore to offer explanations for various types of behavior people actually exhibit. i would therefore not talk of offering explanations.
+%Many things were said multiple times here. I will need to work on it longer still to rid it of all redudancy.
+\section{Reaching the Optimum}
+So far it has been supposed that players in the role of the sender do not care about the harm they inflict when choosing one over the other message. Whether this is an accurate representation of human preferences is beyond the content of this paper. Nonetheless, we want to draw attention to the fact that if this assumption concerning the indifferent stance of the sender is given up, then the employment of different strategies is predicted. More to the point, we can gain clarity under which circumstances agents will play strategies that are Pareto optimal.
% Silvan
\section{The solution}
We have presented the problem of offensive language use \tb{summarize in 1 sentence} and now we will present a solution which can explain offensive and non-offensive language use and puts the speaker in a position to decide between offensive and non-offensive language use. \tb{shorten sentence. These are 2-3 sentences} The core idea is to model the disposition of the speaker towards the receiver. For an example, the speaker can be indifferent, empathetic or even hostile towards the receiver. By modelling this disposition it allows us to make it in the speaker's interest to take the receiver's preferences into account. Furthermore we show that only if the speaker acts empathetically a Pareto optimal solution can be reached.
%Silvan
The core idea is to model the sender's disposition towards the receiver. The sender could be indifferent, empathetic or even hostile towards the receiver. We model this by letting the sender take the receiver's interest into account. We will show that only if the speaker acts in way we'll call \textit{emphatic} a Pareto optimal solution is reached.
+
+As demonstrated before, payoffs could be optimal if senders were to adjust their best response. Until now, however, the strategies leading to such payoffs were not explicitly in the sender's interest and it happens to the player in this role who wields the power to decide over messages. Furthermore, if the players' positions are reversed systematically both players harmed each other by not taking the respective other's interest into account.
+
+At this stage, the solution to this issue becomes apparent: Both players must take the receiver's preferences into account when being in the position to send messages. If the sender does not send receiver costly messages, successful communication is still established and the receiver pays no cost in the process.

%Silvan
We have shown that a optimal strategy can be reached if we adjust the sender's best response. We did not see the optimal strategy in the IBR model since it is not explicitly in the sender's interest to consider the receiver's interests and, coincidentally, it is her who wields the power to decide if an offensive message is sent or not. Furthermore we saw that if we added a third player, nature, to decide the players' positions, both players were worse off if they did not take the other preferences into account. Thus both players must take the receiver's preferences into account and base the response such that is not offensive for the receiver, i.e. the sender must refrain from sending costly messages for the receiver. If the sender does not send receiver costly messages successful communication is still established and the receiver did not incur any cost in the process. Thus a Pareto optimal solution. We therefore adjust the IBR model by adjusting the sender's response such that she takes the receiver's cost into account. \tb{This is good. I would move it right after my first remark in this subsection, and then say what you will do next}

\subsection{Extending the IBR model}
We extend the sender's cost vector to $c^{S*}$ s.t. % use something else for the new cost vector...
$$c^{1*}=c^{1} + d \cdot c^{2}$$
Where $d \in \mathbb{R}$. The best response is defined as previously. \tb{Was this defined previously? If so, no need to say that BR is BR. This is invariant across game theoretical frameworks assuming (expected) utility maximization. However, do explain intuitively what this is doing and how the parameters can be understood. That is, explain why I should think that this is an appropriate modification}
We can now see that by setting $d=0$ we get the original best response since then $c^{1*}=c^{1}$.
Let us now go through the game again with the extended sender's cost. $S_0$ and $R_0$ remain unchanged because these types don't take cost into account at all, so let us start with $S_1$: \tb{Again, I would background the intermediate computations}
\begin{equation*}
S_1= BR_S(R_0^T-c^{1*})=
BR_S(
\bordermatrix{
            & & & &    \cr
 &       1 &         1 & 0       & 0 \cr
 &       0 &         0 & 1      & 1
 }
-
\bordermatrix{
            & & & &    \cr
 &       0 &         \alpha & 0       & d \cdot \beta \cr
 }
)
\end{equation*}
\begin{equation*}
=BR_S(
\bordermatrix{
                & & & &    \cr
     &       1 &         1-\alpha & 0       & 0-d\cdot \beta \cr
     &       0 &         0-\alpha & 1      & 1-d\cdot \beta
 }
 )
 \end{equation*}
We see immediately that depending on the value of $d$ there are different sender responses. If $1<0-d\cdot \beta$ the sender's best response will be to send receiver costly messages over communication.  If $1>1-d\cdot \beta$ the sender's best response will be to send receiver non-costly messages over otihers. We can also see that if $d=1$ the receiver's cost is treated equally to the sender's cost. We define $d=1$ as an \textit{empathetic disposition}. Let us now continue with $d=1$.

\begin{equation*}
S_1=BR_S(
\bordermatrix{
                & & & &    \cr
     &       1 &         1-\alpha & 0       & 0-\beta \cr
     &       0 &         0-\alpha & 1      & 1-\beta
 }
 )
=
\bordermatrix{
                & & & &    \cr
     &       1 &         0 & 0       & 0 \cr
     &       0 &         0 & 1      & 0
 }
 =S_*
 \end{equation*}
$R_1=R_0$ thus $S_2=S_1$ and we end with $S_2$ and $R_2$ as a stable strategies.
\begin{equation*}
  R_2= \bordermatrix{
              &  & \cr
      & 1 & 0 \cr
       & 0.5 & 0.5 \cr
       & 0 & 1 \cr
       & 0.5 & 0.5 \cr
   }
   =R_*
\end{equation*}
And indeed these strategies are Pareto optimal since the expected utility for both players is $a$. Thus we conclude by stating that if the sender takes up an \textit{empathetic disposition} towards the receiver's cost a Pareto optimal solution is reached. \tb{Rephrase to an intuitive 1-2 line summary in words}

\section{Discussion}

\tb{Recapitulate. What was the problem? What did you do to solve it? What is the technical contribution? (Why does IBR fail and what did you have to do to change it). How does this address the initial problem? (What are the predictions?) What's the intuitive take home message? Then add another paragraph explaining shortcomings: When does this fail? What could be made differently? Open questions?}

\subsection{Conclusion}
%Haukur ideas%

\tb{Very briefly: What was the problem and how can it be addressed? Why is it important?}
It is hard to perceive which dispostion is held by the speaker in daily langauge use because we always base our word selection on incomplete information about the sender's preferences.
Being empathetic might strike some poeple as a Dove and Hawk game (clarify better) \tb{Do not introduce new ideas in the conclusion. At latest, do this in the general discussion} but our model does not associate any cost by being empathetic as well as the resources (utility of communication) are shared it really does not makes sense to view empathetic in such a light.

\tb{This should be a very concise summary of the problem, how it was addressed. More than anything: It's a recap of the introduction: Why is this problem interesting and what have we learned?}
\subsection{References}
\end{document}
