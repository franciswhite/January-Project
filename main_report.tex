\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}

\title{%
  Sticks and Stones \\
  \large The pragmatics of harmful language use}

\usepackage{mathptmx} % "times new roman"
\usepackage[a4paper,bindingoffset=0.2in, left=5cm,right=4cm,top=4.5cm,bottom=6.5cm,footskip=.25in]{geometry} % for submission requirements
\usepackage{amssymb}
\usepackage{amsmath, amsthm}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{comment}


\usepackage{color}
\newcommand{\tb}[1]{\textcolor[rgb]{.8,.33,.0}{[TB: #1]}}% prints in orange
\newcommand{\sh}[1]{\textcolor[rgb]{.8,.33,.0}{[TB: #1]}}% prints in orange
\usepackage[normalem]{ulem}

\bibliography{references.bib}
\begin{document}
\maketitle

\section{Introduction}
When Donald Trump was asked to explain calling women ``fat pigs'', ``dogs'', ``slobs'' and ``disgusting animals'' his reply was: ``\textit{I’ve been challenged by so many people, I don’t frankly have time for total political correctness. And to be honest with you, this country doesn’t have time either}''. \tb{Add reference for quote}
%https://www.theguardian.com/us-news/2016/nov/30/political-correctness-how-the-right-invented-phantom-enemy-donald-trump
In contrast to Mr Trump, the authors of the present paper had time. We provide a formal framework in order to analyze the pragmatic phenomenon of harmful use of language. If particular word choices are not a central element in the transmission of information, as tacitly suggested by Mr Trump, and may even be an impediment to the speaker; why may speakers notwithstanding refrain from using certain expressions over others? Under which circumstances speakers are disposed to alter their way of expressing themselves.  We address this question in the context of game theoretic models of natural language use.
Specifically, we analyse situations where a speaker is indifferent about the use of one expression over another, while her audience has a clear preference over them. That is, we model a situation in which the wording of an utterance can have an impact on the listener, despite its irrelevance in terms of information transfer. Cases in point are racial slurs and so-called \textit{trigger words} which cause listeners suffering from postraumatic stress disorder (PTSD) to re-live past trauma \cite{fagan2004confronting, yehuda2002post}. So although two expressions might be semantically identical, choosing one over the other can have a substantial effect on actual communication, depending on who is speaking, and, crucially, who is listening. We thus take the pragmatic slogan seriously that there is far more to communication than the literal meaning of the expressions employed, cf. \cite{grice1975logic}. %Format the cf correctly!
When studying the use of language as the transfer of information, the issue becomes to explain how there can coexist equally good - expressive, accurate, etc. - forms of communication, yet some options are used rather than others.

We will present three core results: First, we offer a formal explanation for the reason why offensive use of language is so persistent. Second, we argue that there is potential for better communication, according to standards of Pareto efficiency. Third, we will argue that the degree of empathy language users exhibit is of crucial importance to reap these benefits. \tb{To save space and make everything more concise, you could add the references to the appropriate sections in this paragraph. E.g. In \S N.N we offer...} or put section references in brackets at the end of each points.

To this end, we us a game theoretic model of rational language use between agents that reason about each others linguistic choices \cite{franke2014pragmatic}. This approach looks to explain and predict pragmatic inferences of natural language users by modeling a back-and-forth reasoning between two agents engaged in conversation.
Our formal contribution is to forgo the common assumption that it is exclusively the player sending a message for whom the word choice is costly. Instead, we will look at situations where the cost a message's recipient faces also varies depending on the expressions employed by the sender.

In section 1 we give a brief introduction to the application of game theory to the study of pragmatics.
Section 2 contains an overview over the particular type of model used in our analysis, while Section 3 uses the model to carry it out.
Section 4: Solution
Section 5: Discussion
Section 6: Conclusion

\section{Game Theory and Pragmatics}
\subsection{Signaling Games}
We model language use as a signaling game. These are sequential games between two players: a sender and a receiver \cite{david1969convention}. The game is player in a particular state of the world, formally an element of set $T$ which represents possibles ways the world could be. Only the sender knows which state this happens to be and would like to transfer this information to the receiver. The receiver, who cannot observe the true state, tries to infer the true state by observing a signal which the sender emits.

The game is then played as follows: After the sender observes the true state of the world $t$ she sends some message $m_i$,  $m_i \in M$.
The receiver then observes the message $m_i$ and points to some $t\in T$ which she thinks holds. If this is the actual $t$, communication was successful.
The players payoff depends on whether communication was successfull and which message was used. The different messages bear a specific cost for each player, formally this is a player-specific cost vector.

A sender's \textit{strategy} is a function from the set of states $T$ to the set of messages $M$; a receiver's strategy is a function $M$ to $T$. Informally, strategies are plans of actions for the players which tell them what to do whenever they get to make a move. We call a strategy \textit{pure} if a player will choose a some action with certainty, that is, always, when confronted with a given situation. In contrast to pure strategies stand
\textit{mixed} strategies where players will choose from various actions, each with a certain probability.

Players are assumed to be payoff maximizers. They will play the strategies which lead to the highest expected utility, denoted by EU.

\subsection{Extension Towards Pragmatics}
Game theoretic modeling has been used for of a variety of phenomena related to information transmission. (\cite{spence1973job, smith1982evolution, cho1987signaling})
In the field of linguistics it was applied to obtain a firmer conceptual grip on Gricean pragmatics.
\sh{Insert references}
Here the communication between (rational) agents is thought of as a game played between interlocutors. Formulating situations where pragmatic phenomena arise with mathematical precision helps in different ways: On the one hand, it allows bridging the gap between theoretical work on pragmatics and experimental data with language users (e.g. \cite{frank2012predicting}). More specifically, it generates testable predictions about language use under a variety of parametrizations, as pertaining to the agent's (limited) rationality, cognitive ability to think multiple steps ahead, their preferences and methods of deciding on what action to take - so-called \textit{choice rules} \cite{galeazzi2017play}
 - or their beliefs about the world. On the other hand, such models may to provide insight into how agents actually arrive at the linguistic behavior they exhibit.
 Indeed, models concerned with pragmatic behavior of linguistic agents are caught between the pressure of trying to accurately predict and fit experimental data and the hope to realistically capture one or the other aspect of a pragmatic phenomenon - to represent ''what actually is going on'', so to speak.

The family of models we will be concerned with tries to capture the agents' mutual reasoning about each other. Which action the players deem optimal for them and perform depends on a process of reasoning about what the respective other believes. The model tries to capture this process of reasoning about what the respective other does, believes that her opponent will do, believes what her opponent will believe that she will do, and so forth.
\subsection{The IBR Model}
We are going to use the \textit{iterated best response} model (IBR) model as our formal framework (for details and discussion see \cite{franke2009signal} and \cite{franke2014pragmatic}). IBR relies on an explicit representation of the agents' beliefs about each other. The interlocutors beliefs are spelled out in a round-for-round manner in order to capture what intuitively could be the described as the epistemic dynamic of: ''I think that you think that I think that you think...etc.''. Language users are represented to have some hierarchically ordered level of sophistication which correspond to the number of steps an agent can reason back and forth between herself and the other agents. The reasoning chain formed by such steps is then a sequence of iterated optimal responses. This chain is bounded by the maximal depth a player of a given level of sophistication - or strategic type - can go to.

Entirely unsophisticated types, players who do not take the opponents reasoning into account at all and are thus completely unstrategic, are assigned the level-0. In the games under discussion in this paper this will mean that senders of level-0 will be only concerned with saying whatever is true according to the semantics of the language fragment in question, while receivers of that level will always interpret a message they receive literally. An agent of level-$k$ then forms some belief about the other's behavior who, by assumption, is of some level $l$, where $k\geq l$. Intuitively, this can be interpreted as the player looking down the sophistication hierarchy in order to build some rational expectation of what the other of some specified level $l\leq k$ will do. We'll also make the common assumption that players of level $k$ expect their opponents to reason exactly one step less than themselves and are thus of level $k-1$.

As in standard signaling games, $T$ is the set of states the players can be in, $M$ the set of messages at the sender's disposal. We assume that $T$ and $M$ are finite sets, $|M|=m$, $|T|=n$. A sender strategy is a row-stochastic $(n \times m)$-matrix $S$, and a receiver strategy is a row-stochastic $(m\times t)$-matrix $R$.
The matrices' entries represent the probability with which the players choose a move in the column - messages for senders, states for receivers - when observing the situation in the row - state for senders, messages for receivers, $P(m|t,S) = S_{tm}$ and likewise $P(t|m,R) = S_{ma}$.

The semantics of the language fragment in question is modeled as a $(n \times m)$-matrix. If a state $t_i$ makes a message $m_j$ true, then the entry $x_{ij}$ in the matrix will be $1$, otherwise $0$. This matrix reporting the boolean values is called the \textit{Boolean Matrix} and denoted by $B$.
Players of level-0 are supposed to be \textit{naive} with respect to sending and receiving messages. Naive senders always send true messages, while naive receivers always take messages literally.
The strategies of level-0 type are represented by the normalized boolean matrix. Normalization here simply means a mapping of some $(m\times n)$-matrix $A$ onto some other $(m\times n)$-matrix $B$ such that $B_i\propto A_i$ if $\sum_j (A_{ij})>0$ and $B_{ij}=\tfrac{1}{n}$ otherwise. In the case of the receiver the transposed boolean matrix is normalized.

More sophisticated players are modeled as to have some belief about the interlocutors behavior. We assume that players view all their oponent's strategies to be equally probable at first. \footnote{This corresponds to unbiased beliefs. We are leaving the details aside for ease of exposition, but see \cite{franke2013pragmatic} for details.}

Finally, we define the notion of \textit{best response} given a set of beliefs. A sender's best response to some receiver strategy $R$ is any strategy that maps each state to that signal which maximizes the expected utility. In case $n$ signals are tied for expected utility, the sender will play each with probability $\tfrac{1}{n}$.
A receiver's best response to a sender's strategy $S$ is defined almost analogously. Except that there may be so-called \textit{surprise messages} $m_j$ for which $R{ij}=0$, for all $i$. These are messages the sender will use with probability 0, that is, never. Since strategies are plans of action for every conceivable contingency that might arise in the course of a game, we'll assume that a receiver will then play each option with probability $\tfrac{1}{|T|}$.

\section{Harmful Signals}
Say two people share some language and engage in conversation, one as a speaker, the other as a listener. The speaker would like to communicate what kind of work a mutual acquaintance of the two does. The listener does not yet know what her occupation happens to be. The acquaintance could either be an ecologist or a geologist. To transfer this knowledge the speaker can utter either ''She's an ecologist.'', ''She's a professional treehugger, stupdily trying to protect plants and stuff.'', ''She's a geologist.'' or ''She's a professional stonehugger, stupidly looking at rocks and stuff.''. Assume that uttering any of the first two is true just in case the person is an ecologist and the last two if she's a geologist. As both of the two well know, the listener cares dearly for the environment, while the speaker does not. The listener, although she understands perfectly well what the speaker is trying to convey to her, would be deeply offended by her uttering the word ''treehugger''. The speaker herself couldn't care less what words are used when talking about ecology, as long as the message comes across and the hearer adopts the right belief about the mutual acquaintance's profession. However, the speaker has a deep-rooted fear of rocks. Hearing the word ''stonehugger'' sends chills down her spine.

Using the IBR framework we can model this as follows.
There are two players, $P_1$ and $P_2$. For now, let $P_1$ be the sender and $P_2$ the receiver. Let $T=\{t_{geo}, t_{eco}\}$, where $t_{geo}$ is a world where the acquaintance is a geologist and in $t_{eco}$ an ecologist. We let both worlds be equally likely. Both receiver and sender get a payoff of $a$ if communication is successful.

The set of messages is $M=\{m_{geo}, m_{stone}, m_{eco}, m_{tree}\}$. Its semantics are given by $B$.
 \begin{equation*}
 B =
 \bordermatrix{
            & m_{geo} & m_{stone} & m_{eco} & m_{tree}    \cr
   t_{geo}  &       1 &         1 & 0       & 0 \cr
   t_{eco}  &       0 &         0 & 1       & 1
 }
 \end{equation*}

$m_{stone}$ being played inflicts a cost of $\alpha$ to $P_1$, while $m_{tree}$ bears cost $\beta$ for $P_2$, where $a>\alpha,\beta>0$.\footnote{Communicating is always preferable to non-communication and no expressions can only be harmful.} Using the same ordering as above, the cost vectors are $c^1=(0,\alpha,0,0)$ and $c^2=(0,0,0,\beta)$. As a first step, we determine what the naive players' strategies are:\\
\textbf{Level-0 Players}\\
\begin{equation*}
S_0=Norm(B)=
\bordermatrix{
            & & & &    \cr
 &       0.5 &         0.5 & 0       & 0 \cr
 &       0 &         0 & 0.5       & 0.5
 }\quad
R_0=Norm(B^T)
\bordermatrix{
            &  & \cr
    & 1 & 0 \cr
     & 1 & 0 \cr
     & 0 & 1 \cr
     & 0 & 1 \cr
 }
\end{equation*}
We can see that the naive sender plays a mixed strategy when whishing to communicate the state, sending either applicable message half of the time. The receiver's actions are clearly determined by a pure strategy.

The best response of a k-level players is based on the interlocutor's k-1 level when message cost taken into account.

We obtain the best response of the level-1 sender by analysing her reasoning about a level-0 receiver. She looks at what a naive receiver would do and then chooses the best answer to that strategy, while accounting for the cost of her own moves. We proceed analogously for the receiver. This then yields strategies for both level-1 players:
\textbf{Level-1 Players}\\
\begin{equation*}
S_1= BR_S(R^T_0-c^1)=
BR_S(
\bordermatrix{
            & & & &    \cr
 &       1 &         1 & 0       & 0 \cr
 &       0 &         0 & 1      & 1
 }
-
\bordermatrix{
            & & & &    \cr
 &       0 &         \alpha & 0       & 0 \cr
 }
)
\end{equation*}
\begin{equation*}
=BR_S(
\bordermatrix{
                & & & &    \cr
     &       1 &         1-\alpha & 0       & 0 \cr
     &       0 &         0-\alpha & 1      & 1
 }
 )
=
\bordermatrix{
                 & & & &    \cr
      &       1 &         0 & 0       & 0 \cr
      &       0 &         0 & 0.5      & 0.5
  }
\end{equation*}
\begin{equation*}
R_1=BR_R({S_0}^T-{c^2}^T)=
BR_R(
\bordermatrix{
            &  & \cr
    & 0.5 & 0 \cr
     & 0.5 & 0 \cr
     & 0 & 0.5 \cr
     & 0 & 0.5 \cr
 }
-
\bordermatrix{
  & \cr
    & 0 \cr
     & 0 \cr
     & 0 \cr
     & \beta \cr
 }
)
\end{equation*}
\begin{equation*}
=
BR_R(
\bordermatrix{
            &  & \cr
    & 0.5 & 0 \cr
     & 0.5 & 0 \cr
     & 0 & 0.5 \cr
     & 0-c & 0.5-c \cr
 }
 )
=
\bordermatrix{
            &  & \cr
    & 1 & 0 \cr
     & 1 & 0 \cr
     & 0 & 1 \cr
     & 0 & 1 \cr
 }
\end{equation*}
We see that $R_1=R_0$, i.e. the receiver did not change strategy from 0-level to 1-level, thus we conclude that $S_2=S_1$. But $S_1 \neq S_0$, so we calculate:
\begin{equation*}
R_2=BR_R({S_1}^T-{c^2}^T)=
\bordermatrix{
            &  & \cr
    & 1 & 0 \cr
     & 0.5 & 0.5 \cr
     & 0 & 1 \cr
     & 0 & 1 \cr
 }
\end{equation*}
$S_3=S_2$ and $R_3=R_2$. Since neither strategy changed from level 2 to level 3 we have reached a fixed point of the reasoning process. That is,  $<S_2,R_2>$ is a stable strategy pair.

Some remarks about these strategies are in order. First, the sender will never send the message she finds offensive. Intuitively, this is because she has a non-costly alternative to choose from. Second, although the sender will never play $m_{stone}$ the receiver still needs has some plan of action for that contingency. Thirdly, while a sender of level zero still harms herself by blindly sending a costly message, senders above level zero will stop doing so. Thus, $m_{stone}$ will not be seen on higher levels. Fourth, and most relevant to our discussion, is that even though the $m_{tree}$ is costly for the receiver, the sender will still send it half of the time. This point is the main focus of the next section.

\subsection{Room for Improvement}
The players' reasonings lead to a situation where communication is successful. Using the stable strategy pair $<S_2,R_2>$ the \textit{sender's payoff} is always $a$. For the receiver, however, the story is different. When $S_2$ is played and $t_{eco}$ holds, $m_{tree}$ will be sent with probability 0.5. Since the probability of $t_{eco}$ is 0.5, $m_{tree}$ is sent in $\tfrac{1}{2}\times \tfrac{1}{2} = \tfrac{1}{4}$ of all cases on average, inflicting a cost of $\beta$. The \textit{receiver's payoff} is a mere $a-\tfrac{\beta}{4}$ as shown in the table below.

\begin{table}[h]
\centering
\caption{Expected Payoff for Level of Sophistication}
\begin{tabular}{lll}
                                    & Sender                                  & Receiver                                \\ \cline{2-3}
\multicolumn{1}{l|}{Level-0}        & \multicolumn{1}{l|}{$a-\tfrac{\alpha}{4}$} & \multicolumn{1}{l|}{$a-\tfrac{\beta}{4}$} \\ \cline{2-3}
\multicolumn{1}{l|}{Level-k, $k>0$} & \multicolumn{1}{l|}{$a$}                  & \multicolumn{1}{l|}{$a-\tfrac{\beta}{4}$} \\ \cline{2-3}
\end{tabular}
\end{table}
To provide some intuition, consider the positions the agents are facing in this game. Whether the receiver likes the message or not, she can always reason what her interlocutor wants to communicate to her. If the messages $m_{geo}$ or $m_{eco}$ are sent, she will chose the corresponding action, communication is successfull, so both players get their payoff and everyone is happy. If the message $m_{tree}$ is sent, however, she pays the associated cost. Still, she knows what the sender is trying to communicate and her best response will be to cooperate. Refusing to understand is not an option, for it would only add insult to injury; she would both pay the cost of hearing $m_{tree}$ and lose the payoff of understanding correctly. Because the sender can anticipate the receiver to behave this way, she does not need to care about sending either true message.

Usually language users will encounter the expressions of their language many times over the course of their communicative lives - both as listeners as well as speakers. To capture this we'll posit a third player - nature - which decides at the beginning of the game who of the two players gets to talk and who gets to listen. Let's assume that nature decides uniformly thus making the game symmetrical with regard to roles. Thus their expected utility in repeated interactions is $\tfrac{1}{2}\times a + \tfrac{1}{2}\times (a-\tfrac{i}{4})=a-\tfrac{i}{8}$, for $i\in \{\alpha,\beta \}$.

The crucial observation here is that the agents could have done better. To see this, imagine the agents only used $m_{eco}$ and $m_{geo}$ to communicate. That is, if they do not inflict cost on each other and communication is still successful, then both receive a full payoff of $a$. Never playing costly messages formally means that the respective sender plays strategy $S_*$ where neither $m_{tree}$ nor $m_{stone}$ are ever played. This leads us to the strategy pair $<S_*,R_*>$:
\begin{equation*}
S_*=
\bordermatrix{
            & & & &    \cr
 &       1 &    0      & 0       & 0 \cr
 &       0 &         0 & 1      & 0
 }\quad
R_*= \bordermatrix{
           &  & \cr
   & 1 & 0 \cr
    & 0.5 & 0.5 \cr
    & 0 & 1 \cr
    & 0.5 & 0.5 \cr
}
\end{equation*}

If this sender strategy is still able to convey the correct state, then everyone is better off or at least as well off as before. Indeed, such an improvement would make the players' payoff meet the standards for \textit{Pareto optimality}. Pareto optimality captures the fact that no player could possibly be better off without the other player losing out. In the present context it means that the potential for better communication is only exhausted, once the players reach Pareto optimality.
Technically speaking, some strategy is Pareto optimal if it is not \textit{Pareto dominated} by any other strategy. We say that the strategy $s'$ \textit{Pareto dominates} $s$, in turn, if $s'$ gives any player a higher utility than $s$, while no other player's utility decreases.
It is straightforward to see that the strategy pair $<S_*,R_*>$ is Pareto optimal since the highest possible utility for either player is $a$ and $<S_*,R_*>$ has utility of $a$ for both players, therefore there is no other strategy which \textit{Pareto dominates} it. Furthermore we see that $<S_*,R_*>$ \textit{Pareto dominates} the IBR strategy which has expected utility of $a-\tfrac{i}{8}$, for $i\in \{\alpha,\beta \}$. In the next section we show that a small adjustment to our model suffices to reach the strategy pairs $<S_*,R_*>$.

\section{Reaching the Optimum}
So far it has been supposed that players in the role of the sender do not care about the harm they inflict when choosing one over the other message. We have seen that the players then arrive at non-optimal strategies because they are indifferent to the respective other's cost. 
However, if this assumption concerning the indifferent stance of the sender is given up, then the employment of different strategies is predicted. We can gain clarity under which circumstances agents will play strategies that are Pareto optimal.

More to the point, we reach the optimal solution if both players must consider receiver's preferences. We do this by extending the sender's cost vector:
$$c^{1*}=c^{1} + d \cdot c^{2}$$
Where $c^{1}$ is the original sender's cost, $c^{2}$ the receiver's cost and $d \in \mathbb{R}$ a parameter representing the players' disposition to ''feel'' the other's cost. Intuitively, if $d>0$ the players are empathetic, if $d<0$ they are malicious and $d=0$ is the indifferent case. By extending the model in this way we can make the sender's interest in the receiver's cost explicit. Setting $d=0$ yields the original model because then $c^{1*}=c^{1}$, for all other values of $d$ we get an extended model. 

What happens when empathetic agents play the game from above? $S_0$ and $R_0$ remain unchanged. So let us start with $S_1$:
\begin{equation*}
S_1= BR_S(R_0^T-c^{1*})=BR_S(
\bordermatrix{
                & & & &    \cr
     &       1 &         1-\alpha & 0       & 0-d\cdot \beta \cr
     &       0 &         0-\alpha & 1      & 1-d\cdot \beta
 }
)
\end{equation*}
Depending on the value of $d$ there are different sender responses. If $1<0-d\cdot \beta$ the sender's best response will be to send receiver costly messages over communication.  If $1>1-d\cdot \beta$ the sender's best response will be to send receiver non-costly messages over otihers. We can also see that if $d=1$ the receiver's cost is treated equally to the sender's cost. We define $d=1$ as an \textit{empathetic disposition}. Let us now continue with $d=1$ and then we get:

\begin{equation*}
S_1=BR_S(
\bordermatrix{
                & & & &    \cr
     &       1 &         1-\alpha & 0       & 0-\beta \cr
     &       0 &         0-\alpha & 1      & 1-\beta
 }
 )
=
\bordermatrix{
                & & & &    \cr
     &       1 &         0 & 0       & 0 \cr
     &       0 &         0 & 1      & 0
 }
 =S_*
 \end{equation*}
$R_1=R_0$ thus $S_2=S_1$ and we end with $S_2$ and $R_2$ as a stable strategies.
\begin{equation*}
  R_2= \bordermatrix{
              &  & \cr
      & 1 & 0 \cr
       & 0.5 & 0.5 \cr
       & 0 & 1 \cr
       & 0.5 & 0.5 \cr
   }
   =R_*
\end{equation*}
As we showed in the previous section, this strategy pair is Pareto optimal. We have therefore extended the IBR model to allow for Pareto optimal solutions when modelling offensive language use by explicitly making it in the sender's interest to not offend the receiver.

% Maybe we add this somewhere:
The core idea is to model the disposition of the speaker towards the receiver. For an example, the speaker can be indifferent, empathetic or even hostile towards the receiver. By modelling this disposition it allows us to make it in the speaker's interest to take the receiver's preferences into account. Furthermore we show that only if the speaker acts empathetically a Pareto optimal solution can be reached.

\section{Discussion}

\tb{Recapitulate. What was the problem? What did you do to solve it? What is the technical contribution? (Why does IBR fail and what did you have to do to change it). How does this address the initial problem? (What are the predictions?) What's the intuitive take home message? Then add another paragraph explaining shortcomings: When does this fail? What could be made differently? Open questions?}

\subsection{Conclusion}
%Haukur ideas%

\tb{Very briefly: What was the problem and how can it be addressed? Why is it important?}
It is hard to perceive which dispostion is held by the speaker in daily langauge use because we always base our word selection on incomplete information about the sender's preferences.
Being empathetic might strike some poeple as a Dove and Hawk game (clarify better) \tb{Do not introduce new ideas in the conclusion. At latest, do this in the general discussion} but our model does not associate any cost by being empathetic as well as the resources (utility of communication) are shared it really does not makes sense to view empathetic in such a light.

\tb{This should be a very concise summary of the problem, how it was addressed. More than anything: It's a recap of the introduction: Why is this problem interesting and what have we learned?}
\subsection{References}
\end{document}